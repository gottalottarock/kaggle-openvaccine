{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from scipy.linalg import block_diag\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_couples(structure):\n",
    "    \"\"\"\n",
    "    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n",
    "    The assigned list is used to keep track of the assigned opening parenthesis\n",
    "    \"\"\"\n",
    "    opened = [idx for idx, i in enumerate(structure) if i == \"(\"]\n",
    "    closed = [idx for idx, i in enumerate(structure) if i == \")\"]\n",
    "\n",
    "    assert len(opened) == len(closed)\n",
    "\n",
    "    assigned = []\n",
    "    couples = []\n",
    "\n",
    "    for close_idx in closed:\n",
    "        for open_idx in opened:\n",
    "            if open_idx < close_idx:\n",
    "                if open_idx not in assigned:\n",
    "                    candidate = open_idx\n",
    "            else:\n",
    "                break\n",
    "        assigned.append(candidate)\n",
    "        couples.append((candidate, close_idx))\n",
    "        assigned.append(close_idx)\n",
    "        couples.append((close_idx, candidate))\n",
    "\n",
    "    assert len(couples) == 2 * len(opened)\n",
    "\n",
    "    return couples\n",
    "\n",
    "\n",
    "def build_matrix(couples, size):\n",
    "    mat = np.zeros((size, size))\n",
    "\n",
    "    for i in range(size):  # neigbouring bases are linked as well\n",
    "        if i < size - 1:\n",
    "            mat[i, i + 1] = 1\n",
    "        if i > 0:\n",
    "            mat[i, i - 1] = 1\n",
    "\n",
    "    for i, j in couples:\n",
    "        mat[i, j] = 2\n",
    "        mat[j, i] = 2\n",
    "\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def seq2nodes(sequence, loop_type):\n",
    "    type_dict={'A':0,'G':1,'U':2,'C':3}\n",
    "    type_loop = {'E': 0, 'H': 1, 'M': 2, 'I': 3, 'X': 4, 'S': 5, 'B': 6}\n",
    "    nodes=np.zeros((len(sequence),4))\n",
    "    loops = np.zeros((len(sequence), len(type_loop)))\n",
    "    for i,(s,lt) in enumerate(zip(sequence, loop_type)):\n",
    "        nodes[i,type_dict[s]]=1\n",
    "        loops[i,type_loop[lt]] = 1\n",
    "    nodes = np.concatenate([nodes, loops],axis=-1)\n",
    "    return nodes\n",
    "\n",
    "def seq2edge_index(structure):\n",
    "    couples = sorted(set(get_couples(structure)))\n",
    "    couples = np.array(couples).T\n",
    "    neig = np.array([np.arange(0,len(structure) -1), np.arange(1,len(structure))])\n",
    "    neig2 = neig[::-1,::]\n",
    "    edge_index = np.concatenate([couples, neig, neig2], axis=1)\n",
    "    edges_type = np.array([1]*couples.shape[1] + [2]*neig.shape[1]*2)\n",
    "\n",
    "    return edge_index, edges_type\n",
    "\n",
    "def edge_index2features(edge_index, edges_type, node_features):\n",
    "    edge_type_f = np.zeros((edge_index.shape[1],2))\n",
    "    for ty in [1,2]:\n",
    "        edge_type_f[:,ty-1] = (edges_type == ty).astype(int)\n",
    "    edge_direction = np.stack([(edge_index[1,] - edge_index[0,] == 1).astype(int),\n",
    "                          (edge_index[0,] - edge_index[1,] == 1).astype(int)]).T\n",
    "    edge_features = np.concatenate([edge_type_f,edge_direction],axis=-1)\n",
    "    return edge_features\n",
    "\n",
    "def seq2edges(structure, node_features):\n",
    "    edge_index, edges_type = seq2edge_index(structure)\n",
    "    edge_features = edge_index2features(edge_index, edges_type, node_features)\n",
    "    return edge_index, edge_features\n",
    "\n",
    "def cg2edges(cg_graph, node2idx):\n",
    "    features = []\n",
    "    indexes = []\n",
    "    for node_name, segments in cg_graph['nodes'].items():\n",
    "        node_idx = node2idx[node_name]\n",
    "        for seg in segments:\n",
    "            for idx in range(*seg):\n",
    "                indexes.append((node_idx,idx))\n",
    "                features.append([1,0,0])\n",
    "                indexes.append((idx, node_idx))\n",
    "                features.append([0,1,0])\n",
    "    for node_1,node_2 in cg_graph['edges']:\n",
    "        indexes.append((node2idx[node_1],node2idx[node_2]))\n",
    "        features.append([0,0,1])\n",
    "    indexes = np.array(indexes).T\n",
    "    features = np.array(features)\n",
    "    return indexes, features\n",
    "\n",
    "def create_edges(structure, node_features, cg_graph,node2idx):\n",
    "    edge_index_nuc, edge_features_nuc = seq2edges(structure, node_features)\n",
    "    edge_index_bungle, edge_features_bungle = cg2edges(cg_graph, node2idx)\n",
    "    edge_index = np.concatenate([edge_index_nuc,edge_index_bungle],axis=1)\n",
    "    edge_from = node_features[edge_index[0,]]\n",
    "    edge_to = node_features[edge_index[1,]]\n",
    "    edge_features = block_diag(edge_features_nuc, edge_features_bungle)\n",
    "    edge_features = np.concatenate([edge_features, edge_from,edge_to],axis=1)\n",
    "    return edge_index, edge_features\n",
    "\n",
    "def bungle_features(cg_nodes):\n",
    "    type_dict = {'f': 0, 't': 1, 's': 2, 'i': 3, 'm': 4, 'h': 5}\n",
    "    features = np.zeros((len(cg_nodes),len(type_dict)+1))\n",
    "    for index, (node_name, segments) in enumerate(cg_nodes.items()):\n",
    "        features[index][type_dict[node_name[0]]] = 1\n",
    "        num_b = sum(seg[1]-seg[0] for seg in segments)\n",
    "        features[index][-1] = num_b\n",
    "    return features\n",
    "\n",
    "def add_bungle_nodes(x, cg_graph):\n",
    "    x = np.concatenate([x,np.ones((x.shape[0],1))], axis=1)\n",
    "    cg_nodes = cg_graph['nodes']\n",
    "    x_len,x_dim = x.shape\n",
    "    node2idx = {node:index for index,node in enumerate(cg_nodes,start=x_len)}\n",
    "    cg_x = bungle_features(cg_nodes)\n",
    "    cg_x = np.concatenate([cg_x,np.ones((cg_x.shape[0],1))], axis=1)\n",
    "    features = block_diag(x, cg_x)\n",
    "    return features, node2idx\n",
    "    \n",
    "\n",
    "def build_data(df, cg_graphs, target_cols=None, error_cols=None):\n",
    "    target_cols = target_cols or []\n",
    "    error_cols = error_cols or []\n",
    "    assert len(error_cols) == len(target_cols)\n",
    "    data_list = []\n",
    "    for (id_, sequence, structure, seq_scored, loop_type), targets, errors in zip(tqdm(df[['id','sequence','structure','seq_scored', 'predicted_loop_type']].values),\n",
    "                                                                       df[target_cols].values, df[error_cols].values):\n",
    "        cg_graph = cg_graphs[id_]\n",
    "        x = seq2nodes(sequence, loop_type)\n",
    "        x, node2idx = add_bungle_nodes(x, cg_graph)\n",
    "        edge_index, edge_features = create_edges(structure, x, cg_graph, node2idx)\n",
    "        if targets is not None:\n",
    "            targets = np.stack(targets).T\n",
    "            errors = np.stack(errors).T\n",
    "            targets = np.pad(targets, ((0,x.shape[0]-targets.shape[0]),(0,0)),constant_values=np.nan)\n",
    "            errors = np.pad(errors, ((0,x.shape[0]-errors.shape[0]),(0,0)),constant_values=np.nan)\n",
    "            targets = torch.FloatTensor(targets)\n",
    "            errors = torch.FloatTensor(errors)\n",
    "            \n",
    "            targets = torch.stack([targets, errors], dim=2)\n",
    "        else:\n",
    "            targets = None\n",
    "\n",
    "        edge_index = torch.LongTensor(edge_index)\n",
    "        edge_features = torch.FloatTensor(edge_features)\n",
    "        x = torch.FloatTensor(x)\n",
    "        data = Data(x, edge_index, edge_features, targets)\n",
    "        data.seq_scored = seq_scored\n",
    "        is_nuc = np.zeros(x.shape[0])\n",
    "        is_nuc[:len(sequence)] = 1\n",
    "        data.is_nuc = torch.BoolTensor(is_nuc)\n",
    "        data_list.append(data)\n",
    "    assert len({data.seq_scored for data in data_list}) == 1\n",
    "    return data_list\n",
    "\n",
    "def simple_graph(bpp, sequence, structure, loop_type, targets, errors):\n",
    "    x = seq2nodes(sequence, loop_type)\n",
    "    matrix = build_matrix(get_couples(structure), len(structure))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "MAP2D_FOLDER = '../data/nsp_distances_angles2/'\n",
    "TARGET_COLS = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']\n",
    "ERROR_COLS = ['reactivity_error', 'deg_error_Mg_pH10','deg_error_Mg_50C']\n",
    "NEPTUNE_API_TOKEN='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiODQwOTM5MjItYWQ2Mi00ODRhLTgxOTUtMzA4NzNhMzI3OGIwIn0='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class MyDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, df_train, df_val, cg_graphs, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.df_train = df_train\n",
    "        self.df_val = df_val\n",
    "        self.cg_graphs = cg_graphs\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_data_list = build_data(self.df_train, self.cg_graphs, target_cols=TARGET_COLS, error_cols=ERROR_COLS)\n",
    "        self.val_data_list = build_data(self.df_val, self.cg_graphs, target_cols=TARGET_COLS, error_cols=ERROR_COLS)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data_list, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data_list, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def compute_MCRMSE(pred, y, columns,per_column=False,prefix=''):\n",
    "    mask = ~y[:,0,0].isnan()\n",
    "    pred = pred[mask]\n",
    "    y = y[:,:,0][mask]\n",
    "    losses = torch.sqrt(torch.mean((pred - y)**2,dim=0) + 1e-6)\n",
    "    if not per_column:\n",
    "        return losses.mean()\n",
    "    metrics = {f\"{prefix}_mcrmse_{col}\" if prefix else f\"mcrmse_{col}\":loss for col,loss in zip(columns, losses)}\n",
    "    metrics[\"mcrmse\"] = losses.mean()\n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class MyGNNLighting(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,input_size, hidden_size, edge_dim, edge_hidden_dim, output_dim=3, seq_len=107, seq_scored=68):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.edge_mlp = nn.Linear(edge_dim, edge_hidden_dim)\n",
    "        self.node_mlp = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size,int(hidden_size/2),bidirectional=True, batch_first=True)\n",
    "        self.gcn = gnn.CGConv(hidden_size, edge_hidden_dim)\n",
    "        self.gcn2 = gnn.CGConv(hidden_size, edge_hidden_dim)\n",
    "        self.gcn3 = gnn.CGConv(hidden_size, edge_hidden_dim)\n",
    "        self.mlp = nn.Linear(hidden_size, output_dim)\n",
    "        self.seq_scored = seq_scored\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data.x.float()\n",
    "        x = self.node_mlp(x)\n",
    "        edge_attr = data.edge_attr\n",
    "        edge_attr = self.edge_mlp(edge_attr)\n",
    "#         for i in range(batch.num_graphs):\n",
    "            \n",
    "#         x = self.lstm(x.view(-1, self.seq_len, x.shape[-1]))[0]\n",
    "#         print(x.shape)\n",
    "#         x = x.reshape(-1,x.shape[-1])\n",
    "        x = self.gcn(x,data.edge_index, edge_attr)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.gcn2(x,data.edge_index, edge_attr)\n",
    "        x = self.gcn3(x,data.edge_index, edge_attr)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pred = self(batch)\n",
    "        y = batch.y\n",
    "        loss = self.compute_loss(pred, y)\n",
    "        result = pl.TrainResult()\n",
    "        result.log(\"train_mcrmse\", loss, on_step=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        pred = self(batch)\n",
    "        y = batch.y\n",
    "        result = pl.TrainResult()\n",
    "        return (pred, y)\n",
    "    \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        pred,y = zip(*validation_step_outputs)\n",
    "        pred = torch.cat(pred,dim=0)\n",
    "        y = torch.cat(y, dim=0)\n",
    "        metrics = self.compute_loss(pred, y, per_column=True, prefix='val')\n",
    "        result = pl.EvalResult(checkpoint_on=metrics['mcrmse'])\n",
    "        result.log_dict(metrics, on_step=False, on_epoch=True, logger=True, prog_bar=False)\n",
    "        return result\n",
    "    \n",
    "    def compute_loss(self, pred, y, columns=TARGET_COLS, per_column=False, prefix=''):\n",
    "        return compute_MCRMSE(pred, y, columns, per_column, prefix=prefix)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = Adam(self.parameters(), lr=1e-2)\n",
    "        return opt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df =  pd.read_json('../data/train.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df[df['SN_filter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_train = df.iloc[:1000]\n",
    "df_test = df.iloc[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data = MyDataModule(df_train,df_test,cg_graph, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for batch in data.val_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "module = MyGNNLighting(data.train_data_list[0].x.shape[1],100,data.train_data_list[0].edge_attr.shape[1],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logger = pl.loggers.neptune.NeptuneLogger(NEPTUNE_API_TOKEN,\"gottalottarock/openVaccine\",experiment_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer = pl.trainer.Trainer(logger=logger,max_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "trainer.fit(module,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_openvaccine",
   "language": "python",
   "name": "graph_openvaccine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
